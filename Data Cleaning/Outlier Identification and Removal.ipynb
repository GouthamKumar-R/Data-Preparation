{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* An outlier is an unlikely observation in a dataset and may have one of many causes.\n",
    "* How to use simple univariate statistics like standard deviation and interquartile range to\n",
    "identify and remove outliers from a data sample.\n",
    "* How to use an outlier detection model to identify and remove rows from a training dataset\n",
    "in order to lift predictive modeling performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TOC:\n",
    "1. Standard Deviation Method\n",
    "2. Interquartile Range Method\n",
    "3. Automatic Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> NOTE :Great care should be taken not to hastily remove or change values, especially if the\n",
    "sample size is small."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Standard deviation method:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we know that the distribution of values in the sample is Gaussian or Gaussian-like, we can\n",
    "use the standard deviation of the sample as a cut-off for identifying outliers.\n",
    "\n",
    "Three standard deviations from the mean is a common cut-off in practice for identifying outliers in a Gaussian or Gaussian-like\n",
    "distribution. \n",
    "\n",
    "For smaller samples of data, perhaps a value of 2 standard deviations (95 percent)\n",
    "can be used, and for larger samples, perhaps a value of 4 standard deviations (99.9 percent) can\n",
    "be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T17:26:44.223483Z",
     "start_time": "2020-11-14T17:26:44.189054Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean : 50.19, std.dev : 4.91\n"
     ]
    }
   ],
   "source": [
    "# generating a test data for identifying outliers\n",
    "# libraries\n",
    "from numpy.random import seed\n",
    "from numpy.random import randn\n",
    "from numpy import mean\n",
    "from numpy import std\n",
    "# to generate the sampe o/p\n",
    "seed(1)\n",
    "# generating univariate observations\n",
    "data = 5*(randn(1000)) + 50   #we are using randn-> to get gaussian dist of mean 0 and std.dev 1\n",
    "# in the above data, we are multiplying gaussian dist with 5 std.dev and moving the mean to 50\n",
    "# summarizing\n",
    "print(\"Mean : %0.2f, std.dev : %0.2f\" %(mean(data), std(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T17:49:09.793027Z",
     "start_time": "2020-11-14T17:49:09.764099Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identified outliers using std.dev method: 29\n",
      "Non-outlier observations: 9971\n"
     ]
    }
   ],
   "source": [
    "# Standard devaition method\n",
    "# summary sts\n",
    "data_mean, data_std = mean(data), std(data)\n",
    "#defining outliers\n",
    "cut_off = data_std * 3\n",
    "lower, upper = (data_mean - cut_off), (data_mean + cut_off)\n",
    "#identifying and storing outilers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print('Identified outliers using std.dev method: %d' % len(outliers))\n",
    "#removing outliers (storing other values- those lie inside 3std.dev)\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print('Non-outlier observations: %d' % len(outliers_removed))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Interquartile Range Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A good statistic for summarizing a non-Gaussian distribution sample of data is the Interquartile\n",
    "Range, or IQR for short"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-14T17:55:51.447092Z",
     "start_time": "2020-11-14T17:55:51.411189Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percentiles: 25th= 46.685, 75th= 53.359, IQR= 6.674\n",
      "Outliers identified using IQR method: 81\n",
      "Non-Outlier observations : 9919\n"
     ]
    }
   ],
   "source": [
    "#IQR method IQR = q75 -q25\n",
    "from numpy import percentile\n",
    "#calculating the 75th and 25th percentiles\n",
    "q25 , q75 = percentile(data,25) , percentile(data,75)\n",
    "IQR = q75 - q25\n",
    "#defining outliers\n",
    "cut_off = IQR * 1.5\n",
    "lower, upper = (q25 -cut_off), (q75+cut_off)\n",
    "print('Percentiles: 25th= %.3f, 75th= %.3f, IQR= %.3f' % (q25, q75, IQR))\n",
    "#identifying and storing outilers\n",
    "outliers = [x for x in data if x < lower or x > upper]\n",
    "print(\"Outliers identified using IQR method: %d\" %(len(outliers)))\n",
    "#removing outliers (storing those values that lie inside the cutoff)\n",
    "outliers_removed = [x for x in data if x >= lower and x <= upper]\n",
    "print(\"Non-Outlier observations : %d\" %(len(outliers_removed)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Automatic Outlier Detection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In machine learning, an approach to tackling the problem of outlier detection is one-class classification."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Local Outlier Factor\n",
    "* Isolation Forest\n",
    "* Minimum Covariance Determinant\n",
    "* One-Class SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T17:09:31.401633Z",
     "start_time": "2020-11-15T17:09:31.356201Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MAE without outlier removal: 3.417 \n",
      "Accuracy of the baseline_model: 76.494\n"
     ]
    }
   ],
   "source": [
    "# Baseline model: \n",
    "# Libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "#load the data\n",
    "df = pd.read_csv('housing.csv', header= None)\n",
    "#storing the data values\n",
    "data = df.values\n",
    "#Split the data into inputs and output elements\n",
    "X, y = data[:,:-1], data[:,-1]\n",
    "#train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.33, random_state =1)\n",
    "#fit the model\n",
    "model= LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "#evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "#evaluate predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print(\"MAE without outlier removal: %0.3f \" %(mae))\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy of the baseline_model: %0.3f\" %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Local Outlier Factor : LOF  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The local outlier factor, or LOF for short, is a technique that attempts to harness the idea of nearest neighbors for outlier\n",
    "detection.\n",
    "\n",
    "Each example is assigned a scoring of how isolated or how likely it is to be outliers based on the size of its local neighborhood. Those examples with the largest score are more likely to be outliers.\n",
    "\n",
    "This can work well for feature spaces with low dimensionality (few features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T17:26:08.284525Z",
     "start_time": "2020-11-15T17:26:08.236676Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "Training ds:\n",
      " (339, 13) (167, 13) \n",
      "Test ds:\n",
      " (339,) (167,)\n",
      "Updated training dataset:\n",
      "(305, 13) (305,)\n",
      "MAE model after=> LOF : 3.356\n",
      "Accuracy of the model: 77.195\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "from sklearn.neighbors import LocalOutlierFactor\n",
    "#load the data\n",
    "df = pd.read_csv('housing.csv', header=None)\n",
    "#store the data for np operations\n",
    "data = df.values\n",
    "#split the data into input and output elements\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "#summarizing the shape\n",
    "print(X.shape, y.shape)\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=1)\n",
    "#summarise the train test shape\n",
    "print(\"Training ds:\\n\",X_train.shape, X_test.shape,\"\\nTest ds:\\n\",y_train.shape, y_test.shape)\n",
    "\n",
    "#Identify the outliers\n",
    "lof = LocalOutlierFactor()\n",
    "yhat = lof.fit_predict(X_train)\n",
    "#select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train , y_train = X_train[mask, :] , y_train[mask]\n",
    "#summary of updated traning dataset\n",
    "print(\"Updated training dataset:\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "#fit the model\n",
    "model= LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "#evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "#evaluate the predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print(\"MAE model after=> LOF : %0.3f\" %mae)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy of the model: %0.3f\" %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Isolation Forest : iForest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Isolation Forest, or iForest for short, is a tree-based anomaly detection algorithm.\n",
    "\n",
    "It is based on modeling the normal data in such a way as to isolate anomalies that are both few in number and different in the feature space.\n",
    "\n",
    "… our proposed method takes advantage of two anomalies’ quantitative properties: i) they are the minority consisting of fewer instances and ii) they have attribute-values that are very different from those of normal instances.`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T17:26:10.082981Z",
     "start_time": "2020-11-15T17:26:09.743726Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "Training ds:\n",
      " (339, 13) (167, 13) \n",
      "Test ds:\n",
      " (339,) (167,)\n",
      "Updated training dataset:\n",
      "(305, 13) (305,)\n",
      "MAE model after=> Iso : 3.199\n",
      "Accuracy of the model: 78.128\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "from sklearn.ensemble import IsolationForest\n",
    "#load the data\n",
    "df = pd.read_csv('housing.csv', header=None)\n",
    "#store the data for np operations\n",
    "data = df.values\n",
    "#split the data into input and output elements\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "#summarizing the shape\n",
    "print(X.shape, y.shape)\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=1)\n",
    "#summarise the train test shape\n",
    "print(\"Training ds:\\n\",X_train.shape, X_test.shape,\"\\nTest ds:\\n\",y_train.shape, y_test.shape)\n",
    "\n",
    "#Identify the outliers\n",
    "iso = IsolationForest(contamination=0.1)  #“contamination” is used to help estimate the no. of outliers in the ds. \n",
    "#This is a value between 0.0 and 0.5 and by default is set to 0.1.\n",
    "yhat = iso.fit_predict(X_train)\n",
    "#select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train , y_train = X_train[mask, :] , y_train[mask]\n",
    "#summary of updated traning dataset\n",
    "print(\"Updated training dataset:\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "#fit the model\n",
    "model= LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "#evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "#evaluate the predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print(\"MAE model after=> Iso : %0.3f\" %mae)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy of the model: %0.3f\" %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Minimum Covariance Determinant : MCD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the input variables have a Gaussian distribution, then simple statistical methods can be used to detect outliers.\n",
    "\n",
    "For example, if the dataset has two input variables and both are Gaussian, then the feature space forms a multi-dimensional Gaussian and knowledge of this distribution can be used to identify values far from the distribution.\n",
    "\n",
    "This approach can be generalized by defining a hypersphere (ellipsoid) that covers the normal data, and data that falls outside this shape is considered an outlier. An efficient implementation of this technique for multivariate data is known as the Minimum Covariance Determinant, or MCD for short."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> The Minimum Covariance Determinant (MCD) method is a highly robust estimator of multivariate location and scatter, for which a fast algorithm is available. […] It also serves as a convenient and efficient tool for outlier detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T17:26:15.207648Z",
     "start_time": "2020-11-15T17:26:15.075502Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "Training ds:\n",
      " (339, 13) (167, 13) \n",
      "Test ds:\n",
      " (339,) (167,)\n",
      "Updated training dataset:\n",
      "(305, 13) (305,)\n",
      "MAE model after=> MCD : 3.686\n",
      "Accuracy of the model: 73.093\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "from sklearn.covariance import EllipticEnvelope\n",
    "#load the data\n",
    "df = pd.read_csv('housing.csv', header=None)\n",
    "#store the data for np operations\n",
    "data = df.values\n",
    "#split the data into input and output elements\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "#summarizing the shape\n",
    "print(X.shape, y.shape)\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=1)\n",
    "#summarise the train test shape\n",
    "print(\"Training ds:\\n\",X_train.shape, X_test.shape,\"\\nTest ds:\\n\",y_train.shape, y_test.shape)\n",
    "\n",
    "#Identify the outliers\n",
    "ee = EllipticEnvelope(contamination=0.1)  #“contamination” here defines the expected ratio of outliers to be observed in practice. \n",
    "#we will set it to a value of 0.01, found with a little trial and error.\n",
    "yhat = ee.fit_predict(X_train)\n",
    "#select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train , y_train = X_train[mask, :] , y_train[mask]\n",
    "#summary of updated traning dataset\n",
    "print(\"Updated training dataset:\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "#fit the model\n",
    "model= LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "#evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "#evaluate the predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print(\"MAE model after=> MCD : %0.3f\" %mae)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy of the model: %0.3f\" %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### One-Class SVM : "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The support vector machine, or SVM, algorithm developed initially for binary classification can be used for one-class classification.\n",
    "\n",
    "When modeling one class, the algorithm captures the density of the majority class and classifies examples on the extremes of the density function as outliers. This modification of SVM is referred to as One-Class SVM; One-Class SVM is also a classification algorithm, it can be used to discover outliers in input data for both regression and classification datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-11-15T17:26:19.268803Z",
     "start_time": "2020-11-15T17:26:19.199985Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(506, 13) (506,)\n",
      "Training ds:\n",
      " (339, 13) (167, 13) \n",
      "Test ds:\n",
      " (339,) (167,)\n",
      "Updated training dataset:\n",
      "(336, 13) (336,)\n",
      "MAE model after=> MCD : 3.431\n",
      "Accuracy of the model: 76.438\n"
     ]
    }
   ],
   "source": [
    "#libraries\n",
    "from sklearn.svm import OneClassSVM\n",
    "#load the data\n",
    "df = pd.read_csv('housing.csv', header=None)\n",
    "#store the data for np operations\n",
    "data = df.values\n",
    "#split the data into input and output elements\n",
    "X = data[:,:-1]\n",
    "y = data[:,-1]\n",
    "#summarizing the shape\n",
    "print(X.shape, y.shape)\n",
    "#train test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=1)\n",
    "#summarise the train test shape\n",
    "print(\"Training ds:\\n\",X_train.shape, X_test.shape,\"\\nTest ds:\\n\",y_train.shape, y_test.shape)\n",
    "\n",
    "#Identify the outliers\n",
    "svm = OneClassSVM(nu=0.01)  #“nu” argument that specifies the approximate ratio of outliers in the dataset\n",
    "#we will set it to a value of 0.01, found with a little trial and error.\n",
    "yhat = svm.fit_predict(X_train)\n",
    "#select all rows that are not outliers\n",
    "mask = yhat != -1\n",
    "X_train , y_train = X_train[mask, :] , y_train[mask]\n",
    "#summary of updated traning dataset\n",
    "print(\"Updated training dataset:\")\n",
    "print(X_train.shape, y_train.shape)\n",
    "#fit the model\n",
    "model= LinearRegression()\n",
    "model.fit(X_train,y_train)\n",
    "#evaluate the model\n",
    "yhat = model.predict(X_test)\n",
    "#evaluate the predictions\n",
    "mae = mean_absolute_error(y_test, yhat)\n",
    "print(\"MAE model after=> MCD : %0.3f\" %mae)\n",
    "\n",
    "accuracy = model.score(X_test, y_test)\n",
    "print(\"Accuracy of the model: %0.3f\" %(accuracy*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## API :"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Isolation Forest : \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.IsolationForest.html\n",
    "\n",
    "* Local Outlier Factor :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.LocalOutlierFactor.html\n",
    "\n",
    "* Min Cov Determinant :\n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.covariance.EllipticEnvelope.html\n",
    "\n",
    "* One class SVM : \n",
    "https://scikit-learn.org/stable/modules/generated/sklearn.svm.OneClassSVM.html\n",
    "\n",
    "* https://scikit-learn.org/stable/modules/outlier_detection.html\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
